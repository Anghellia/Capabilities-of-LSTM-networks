{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKxPT9OtU0S-"
   },
   "outputs": [],
   "source": [
    "# Импортируем библиотеки\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PD4wPEz2UAem"
   },
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    n = len(sequence)\n",
    "    X, y = list(), list()\n",
    "    for i in range(n):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > n-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocHq9qOIuTzO"
   },
   "outputs": [],
   "source": [
    "def plot_difference(true_sequence, predict_values, unit):\n",
    "    print(f'Prediction of model with {unit}:')\n",
    "    df = pd.DataFrame({'real value': true_sequence, 'predicted value': np.round(predict_values, 3), 'difference': np.round(abs(true_sequence-predict_values), 1)})\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NeKFWpves9I"
   },
   "source": [
    "# **Prediction of arithmetic progression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RpjI5ZIXTjNj"
   },
   "source": [
    "$a_n = a_1 + (n-1)*d$  \n",
    "\n",
    "Пусть $d=15$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-Bdby3aTjgB"
   },
   "source": [
    "##**Data generation**#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtenYsCELEp_"
   },
   "outputs": [],
   "source": [
    "def generate_arithmetic_progression(n_steps=4, d=15): # d - шаг арифметической прогрессии\n",
    "\n",
    "    num = 700\n",
    "    batch_size = 2000\n",
    "    i = 0\n",
    "    \n",
    "    X = np.empty((batch_size, n_steps))\n",
    "    y = np.empty((batch_size, 1))\n",
    "\n",
    "    start_val = 10\n",
    "\n",
    "    while i < batch_size:\n",
    "    \n",
    "        array =  np.arange(start_val, start_val +(num-1)*d + 1, d)\n",
    "        j = 0\n",
    "\n",
    "        while j <= num - (n_steps + 1):\n",
    "            if i >= batch_size: break\n",
    "            X[i, :] = array[j:n_steps+j]\n",
    "            y[i, :] = array[j+n_steps]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        \n",
    "        start_val -= 1\n",
    "        \n",
    "    _, index = np.unique(X, axis=0, return_index=True)\n",
    "    X, y = X[index], y[index]\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "OQ_s5Sn6MrYm",
    "outputId": "4afcbd51-7359-4510-b960-b282c2cb74a8"
   },
   "outputs": [],
   "source": [
    "n_steps = 4\n",
    "X_train, y_train = generate_arithmetic_progression(n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "CEm205SMo0xq",
    "outputId": "1720897b-db7f-4b42-f231-f39adaa92d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (2000, 4, 1)\n",
      "y_train shape is (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape is {X_train.shape}')\n",
    "print(f'y_train shape is {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sDitZDYadLe"
   },
   "source": [
    "## **Training model with one LSTM layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smHDKs5EAHLa"
   },
   "outputs": [],
   "source": [
    "def predict(true_sequence, model):\n",
    "    predict_values = true_sequence[:n_steps]\n",
    "    k = n_steps\n",
    "    length = true_sequence.size\n",
    "    while k != length:\n",
    "        X = predict_values[-n_steps::]\n",
    "        X = X.reshape((1, n_steps, 1))\n",
    "        f_x = np.round(model.predict(X, verbose=0))\n",
    "        predict_values = np.append(predict_values, f_x)\n",
    "        k += 1\n",
    "    return predict_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6Odj8IwAIzK"
   },
   "outputs": [],
   "source": [
    "sequence = np.arange(8111, 9000, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3XT0T7hxqm2z",
    "outputId": "5b3e7f78-3c4c-4701-bdbc-fa17b0533bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units in LSTM layer: 1, MSE is: 68403615.0\n",
      "Prediction of model with 1:\n",
      "    real value  predicted value  difference\n",
      "0         8111           8111.0         0.0\n",
      "1         8126           8126.0         0.0\n",
      "2         8141           8141.0         0.0\n",
      "3         8156           8156.0         0.0\n",
      "4         8171             26.0      8145.0\n",
      "5         8186             26.0      8160.0\n",
      "6         8201             26.0      8175.0\n",
      "7         8216             26.0      8190.0\n",
      "8         8231             26.0      8205.0\n",
      "9         8246             26.0      8220.0\n",
      "10        8261             26.0      8235.0\n",
      "11        8276             26.0      8250.0\n",
      "12        8291             26.0      8265.0\n",
      "13        8306             26.0      8280.0\n",
      "14        8321             26.0      8295.0\n",
      "15        8336             26.0      8310.0\n",
      "16        8351             26.0      8325.0\n",
      "17        8366             26.0      8340.0\n",
      "18        8381             26.0      8355.0\n",
      "19        8396             26.0      8370.0\n",
      "20        8411             26.0      8385.0\n",
      "21        8426             26.0      8400.0\n",
      "22        8441             26.0      8415.0\n",
      "23        8456             26.0      8430.0\n",
      "24        8471             26.0      8445.0\n",
      "25        8486             26.0      8460.0\n",
      "26        8501             26.0      8475.0\n",
      "27        8516             26.0      8490.0\n",
      "28        8531             26.0      8505.0\n",
      "29        8546             26.0      8520.0\n",
      "30        8561             26.0      8535.0\n",
      "31        8576             26.0      8550.0\n",
      "32        8591             26.0      8565.0\n",
      "33        8606             26.0      8580.0\n",
      "34        8621             26.0      8595.0\n",
      "35        8636             26.0      8610.0\n",
      "36        8651             26.0      8625.0\n",
      "37        8666             26.0      8640.0\n",
      "38        8681             26.0      8655.0\n",
      "39        8696             26.0      8670.0\n",
      "40        8711             26.0      8685.0\n",
      "41        8726             26.0      8700.0\n",
      "42        8741             26.0      8715.0\n",
      "43        8756             26.0      8730.0\n",
      "44        8771             26.0      8745.0\n",
      "45        8786             26.0      8760.0\n",
      "46        8801             26.0      8775.0\n",
      "47        8816             26.0      8790.0\n",
      "48        8831             26.0      8805.0\n",
      "49        8846             26.0      8820.0\n",
      "50        8861             26.0      8835.0\n",
      "51        8876             26.0      8850.0\n",
      "52        8891             26.0      8865.0\n",
      "53        8906             26.0      8880.0\n",
      "54        8921             26.0      8895.0\n",
      "55        8936             26.0      8910.0\n",
      "56        8951             26.0      8925.0\n",
      "57        8966             26.0      8940.0\n",
      "58        8981             26.0      8955.0\n",
      "59        8996             26.0      8970.0\n",
      "Units in LSTM layer: 2, MSE is: 68419589.9333\n",
      "Units in LSTM layer: 3, MSE is: 10630.55\n",
      "Units in LSTM layer: 4, MSE is: 14221.0\n",
      "Units in LSTM layer: 5, MSE is: 68387913.4167\n",
      "Units in LSTM layer: 6, MSE is: 8423.05\n",
      "Units in LSTM layer: 7, MSE is: 1094.1167\n",
      "Units in LSTM layer: 8, MSE is: 0.0\n",
      "Units in LSTM layer: 9, MSE is: 0.0\n",
      "Units in LSTM layer: 10, MSE is: 0.0\n",
      "Prediction of model with 10:\n",
      "    real value  predicted value  difference\n",
      "0         8111           8111.0         0.0\n",
      "1         8126           8126.0         0.0\n",
      "2         8141           8141.0         0.0\n",
      "3         8156           8156.0         0.0\n",
      "4         8171           8171.0         0.0\n",
      "5         8186           8186.0         0.0\n",
      "6         8201           8201.0         0.0\n",
      "7         8216           8216.0         0.0\n",
      "8         8231           8231.0         0.0\n",
      "9         8246           8246.0         0.0\n",
      "10        8261           8261.0         0.0\n",
      "11        8276           8276.0         0.0\n",
      "12        8291           8291.0         0.0\n",
      "13        8306           8306.0         0.0\n",
      "14        8321           8321.0         0.0\n",
      "15        8336           8336.0         0.0\n",
      "16        8351           8351.0         0.0\n",
      "17        8366           8366.0         0.0\n",
      "18        8381           8381.0         0.0\n",
      "19        8396           8396.0         0.0\n",
      "20        8411           8411.0         0.0\n",
      "21        8426           8426.0         0.0\n",
      "22        8441           8441.0         0.0\n",
      "23        8456           8456.0         0.0\n",
      "24        8471           8471.0         0.0\n",
      "25        8486           8486.0         0.0\n",
      "26        8501           8501.0         0.0\n",
      "27        8516           8516.0         0.0\n",
      "28        8531           8531.0         0.0\n",
      "29        8546           8546.0         0.0\n",
      "30        8561           8561.0         0.0\n",
      "31        8576           8576.0         0.0\n",
      "32        8591           8591.0         0.0\n",
      "33        8606           8606.0         0.0\n",
      "34        8621           8621.0         0.0\n",
      "35        8636           8636.0         0.0\n",
      "36        8651           8651.0         0.0\n",
      "37        8666           8666.0         0.0\n",
      "38        8681           8681.0         0.0\n",
      "39        8696           8696.0         0.0\n",
      "40        8711           8711.0         0.0\n",
      "41        8726           8726.0         0.0\n",
      "42        8741           8741.0         0.0\n",
      "43        8756           8756.0         0.0\n",
      "44        8771           8771.0         0.0\n",
      "45        8786           8786.0         0.0\n",
      "46        8801           8801.0         0.0\n",
      "47        8816           8816.0         0.0\n",
      "48        8831           8831.0         0.0\n",
      "49        8846           8846.0         0.0\n",
      "50        8861           8861.0         0.0\n",
      "51        8876           8876.0         0.0\n",
      "52        8891           8891.0         0.0\n",
      "53        8906           8906.0         0.0\n",
      "54        8921           8921.0         0.0\n",
      "55        8936           8936.0         0.0\n",
      "56        8951           8951.0         0.0\n",
      "57        8966           8966.0         0.0\n",
      "58        8981           8981.0         0.0\n",
      "59        8996           8996.0         0.0\n",
      "Units in LSTM layer: 15, MSE is: 521940.8667\n",
      "Units in LSTM layer: 20, MSE is: 19293.45\n",
      "Prediction of model with 20:\n",
      "    real value  predicted value  difference\n",
      "0         8111           8111.0         0.0\n",
      "1         8126           8126.0         0.0\n",
      "2         8141           8141.0         0.0\n",
      "3         8156           8156.0         0.0\n",
      "4         8171           8178.0         7.0\n",
      "5         8186           8194.0         8.0\n",
      "6         8201           8213.0        12.0\n",
      "7         8216           8234.0        18.0\n",
      "8         8231           8250.0        19.0\n",
      "9         8246           8271.0        25.0\n",
      "10        8261           8290.0        29.0\n",
      "11        8276           8307.0        31.0\n",
      "12        8291           8329.0        38.0\n",
      "13        8306           8346.0        40.0\n",
      "14        8321           8365.0        44.0\n",
      "15        8336           8386.0        50.0\n",
      "16        8351           8403.0        52.0\n",
      "17        8366           8423.0        57.0\n",
      "18        8381           8443.0        62.0\n",
      "19        8396           8460.0        64.0\n",
      "20        8411           8481.0        70.0\n",
      "21        8426           8500.0        74.0\n",
      "22        8441           8518.0        77.0\n",
      "23        8456           8539.0        83.0\n",
      "24        8471           8557.0        86.0\n",
      "25        8486           8577.0        91.0\n",
      "26        8501           8597.0        96.0\n",
      "27        8516           8615.0        99.0\n",
      "28        8531           8636.0       105.0\n",
      "29        8546           8655.0       109.0\n",
      "30        8561           8674.0       113.0\n",
      "31        8576           8695.0       119.0\n",
      "32        8591           8713.0       122.0\n",
      "33        8606           8733.0       127.0\n",
      "34        8621           8753.0       132.0\n",
      "35        8636           8772.0       136.0\n",
      "36        8651           8792.0       141.0\n",
      "37        8666           8812.0       146.0\n",
      "38        8681           8831.0       150.0\n",
      "39        8696           8851.0       155.0\n",
      "40        8711           8871.0       160.0\n",
      "41        8726           8890.0       164.0\n",
      "42        8741           8911.0       170.0\n",
      "43        8756           8930.0       174.0\n",
      "44        8771           8950.0       179.0\n",
      "45        8786           8970.0       184.0\n",
      "46        8801           8989.0       188.0\n",
      "47        8816           9010.0       194.0\n",
      "48        8831           9029.0       198.0\n",
      "49        8846           9049.0       203.0\n",
      "50        8861           9070.0       209.0\n",
      "51        8876           9089.0       213.0\n",
      "52        8891           9110.0       219.0\n",
      "53        8906           9130.0       224.0\n",
      "54        8921           9150.0       229.0\n",
      "55        8936           9171.0       235.0\n",
      "56        8951           9190.0       239.0\n",
      "57        8966           9211.0       245.0\n",
      "58        8981           9231.0       250.0\n",
      "59        8996           9251.0       255.0\n",
      "Units in LSTM layer: 25, MSE is: 0.0\n",
      "Units in LSTM layer: 30, MSE is: 1056.15\n",
      "Units in LSTM layer: 35, MSE is: 0.0\n",
      "Units in LSTM layer: 40, MSE is: 0.0\n",
      "Prediction of model with 40:\n",
      "    real value  predicted value  difference\n",
      "0         8111           8111.0         0.0\n",
      "1         8126           8126.0         0.0\n",
      "2         8141           8141.0         0.0\n",
      "3         8156           8156.0         0.0\n",
      "4         8171           8171.0         0.0\n",
      "5         8186           8186.0         0.0\n",
      "6         8201           8201.0         0.0\n",
      "7         8216           8216.0         0.0\n",
      "8         8231           8231.0         0.0\n",
      "9         8246           8246.0         0.0\n",
      "10        8261           8261.0         0.0\n",
      "11        8276           8276.0         0.0\n",
      "12        8291           8291.0         0.0\n",
      "13        8306           8306.0         0.0\n",
      "14        8321           8321.0         0.0\n",
      "15        8336           8336.0         0.0\n",
      "16        8351           8351.0         0.0\n",
      "17        8366           8366.0         0.0\n",
      "18        8381           8381.0         0.0\n",
      "19        8396           8396.0         0.0\n",
      "20        8411           8411.0         0.0\n",
      "21        8426           8426.0         0.0\n",
      "22        8441           8441.0         0.0\n",
      "23        8456           8456.0         0.0\n",
      "24        8471           8471.0         0.0\n",
      "25        8486           8486.0         0.0\n",
      "26        8501           8501.0         0.0\n",
      "27        8516           8516.0         0.0\n",
      "28        8531           8531.0         0.0\n",
      "29        8546           8546.0         0.0\n",
      "30        8561           8561.0         0.0\n",
      "31        8576           8576.0         0.0\n",
      "32        8591           8591.0         0.0\n",
      "33        8606           8606.0         0.0\n",
      "34        8621           8621.0         0.0\n",
      "35        8636           8636.0         0.0\n",
      "36        8651           8651.0         0.0\n",
      "37        8666           8666.0         0.0\n",
      "38        8681           8681.0         0.0\n",
      "39        8696           8696.0         0.0\n",
      "40        8711           8711.0         0.0\n",
      "41        8726           8726.0         0.0\n",
      "42        8741           8741.0         0.0\n",
      "43        8756           8756.0         0.0\n",
      "44        8771           8771.0         0.0\n",
      "45        8786           8786.0         0.0\n",
      "46        8801           8801.0         0.0\n",
      "47        8816           8816.0         0.0\n",
      "48        8831           8831.0         0.0\n",
      "49        8846           8846.0         0.0\n",
      "50        8861           8861.0         0.0\n",
      "51        8876           8876.0         0.0\n",
      "52        8891           8891.0         0.0\n",
      "53        8906           8906.0         0.0\n",
      "54        8921           8921.0         0.0\n",
      "55        8936           8936.0         0.0\n",
      "56        8951           8951.0         0.0\n",
      "57        8966           8966.0         0.0\n",
      "58        8981           8981.0         0.0\n",
      "59        8996           8996.0         0.0\n",
      "Units in LSTM layer: 45, MSE is: 1002.3333\n",
      "Units in LSTM layer: 50, MSE is: 81.95\n",
      "Units in LSTM layer: 55, MSE is: 0.0\n",
      "Units in LSTM layer: 60, MSE is: 0.0\n"
     ]
    }
   ],
   "source": [
    "units_number = list(range(1, 11)) + list(range(15, 65, 5))\n",
    "losses = []\n",
    "min_loss = None\n",
    "min_unit = None\n",
    "\n",
    "for unit in units_number: \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(unit, activation='softplus', input_shape=(n_steps, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=300, validation_split=0.2, verbose=0)\n",
    "\n",
    "    predict_y = predict(sequence, model)\n",
    "    mse = mean_squared_error(sequence, predict_y)\n",
    "\n",
    "    if min_loss is None or mse < min_loss:\n",
    "         min_unit = unit\n",
    "         min_loss = mse\n",
    "         best_model = model\n",
    "    losses.append(mse)\n",
    "    \n",
    "    print(f'Units in LSTM layer: {unit}, MSE is: {np.round(mse, 4)}')\n",
    "    if unit in (1, 10, 20, 40):\n",
    "        plot_difference(sequence, predict_y, unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AXHmd4e1vSiS",
    "outputId": "7793fcf2-3599-40b7-cd31-f8cff5823230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse is 0.0\n",
      "Prediction of model with 8:\n",
      "     real value  predicted value  difference\n",
      "0          4353           4353.0         0.0\n",
      "1          4368           4368.0         0.0\n",
      "2          4383           4383.0         0.0\n",
      "3          4398           4398.0         0.0\n",
      "4          4413           4413.0         0.0\n",
      "5          4428           4428.0         0.0\n",
      "6          4443           4443.0         0.0\n",
      "7          4458           4458.0         0.0\n",
      "8          4473           4473.0         0.0\n",
      "9          4488           4488.0         0.0\n",
      "10         4503           4503.0         0.0\n",
      "11         4518           4518.0         0.0\n",
      "12         4533           4533.0         0.0\n",
      "13         4548           4548.0         0.0\n",
      "14         4563           4563.0         0.0\n",
      "15         4578           4578.0         0.0\n",
      "16         4593           4593.0         0.0\n",
      "17         4608           4608.0         0.0\n",
      "18         4623           4623.0         0.0\n",
      "19         4638           4638.0         0.0\n",
      "20         4653           4653.0         0.0\n",
      "21         4668           4668.0         0.0\n",
      "22         4683           4683.0         0.0\n",
      "23         4698           4698.0         0.0\n",
      "24         4713           4713.0         0.0\n",
      "25         4728           4728.0         0.0\n",
      "26         4743           4743.0         0.0\n",
      "27         4758           4758.0         0.0\n",
      "28         4773           4773.0         0.0\n",
      "29         4788           4788.0         0.0\n",
      "30         4803           4803.0         0.0\n",
      "31         4818           4818.0         0.0\n",
      "32         4833           4833.0         0.0\n",
      "33         4848           4848.0         0.0\n",
      "34         4863           4863.0         0.0\n",
      "35         4878           4878.0         0.0\n",
      "36         4893           4893.0         0.0\n",
      "37         4908           4908.0         0.0\n",
      "38         4923           4923.0         0.0\n",
      "39         4938           4938.0         0.0\n",
      "40         4953           4953.0         0.0\n",
      "41         4968           4968.0         0.0\n",
      "42         4983           4983.0         0.0\n",
      "43         4998           4998.0         0.0\n",
      "44         5013           5013.0         0.0\n",
      "45         5028           5028.0         0.0\n",
      "46         5043           5043.0         0.0\n",
      "47         5058           5058.0         0.0\n",
      "48         5073           5073.0         0.0\n",
      "49         5088           5088.0         0.0\n",
      "50         5103           5103.0         0.0\n",
      "51         5118           5118.0         0.0\n",
      "52         5133           5133.0         0.0\n",
      "53         5148           5148.0         0.0\n",
      "54         5163           5163.0         0.0\n",
      "55         5178           5178.0         0.0\n",
      "56         5193           5193.0         0.0\n",
      "57         5208           5208.0         0.0\n",
      "58         5223           5223.0         0.0\n",
      "59         5238           5238.0         0.0\n",
      "60         5253           5253.0         0.0\n",
      "61         5268           5268.0         0.0\n",
      "62         5283           5283.0         0.0\n",
      "63         5298           5298.0         0.0\n",
      "64         5313           5313.0         0.0\n",
      "65         5328           5328.0         0.0\n",
      "66         5343           5343.0         0.0\n",
      "67         5358           5358.0         0.0\n",
      "68         5373           5373.0         0.0\n",
      "69         5388           5388.0         0.0\n",
      "70         5403           5403.0         0.0\n",
      "71         5418           5418.0         0.0\n",
      "72         5433           5433.0         0.0\n",
      "73         5448           5448.0         0.0\n",
      "74         5463           5463.0         0.0\n",
      "75         5478           5478.0         0.0\n",
      "76         5493           5493.0         0.0\n",
      "77         5508           5508.0         0.0\n",
      "78         5523           5523.0         0.0\n",
      "79         5538           5538.0         0.0\n",
      "80         5553           5553.0         0.0\n",
      "81         5568           5568.0         0.0\n",
      "82         5583           5583.0         0.0\n",
      "83         5598           5598.0         0.0\n",
      "84         5613           5613.0         0.0\n",
      "85         5628           5628.0         0.0\n",
      "86         5643           5643.0         0.0\n",
      "87         5658           5658.0         0.0\n",
      "88         5673           5673.0         0.0\n",
      "89         5688           5688.0         0.0\n",
      "90         5703           5703.0         0.0\n",
      "91         5718           5718.0         0.0\n",
      "92         5733           5733.0         0.0\n",
      "93         5748           5748.0         0.0\n",
      "94         5763           5763.0         0.0\n",
      "95         5778           5778.0         0.0\n",
      "96         5793           5793.0         0.0\n",
      "97         5808           5808.0         0.0\n",
      "98         5823           5823.0         0.0\n",
      "99         5838           5838.0         0.0\n",
      "100        5853           5853.0         0.0\n",
      "101        5868           5868.0         0.0\n",
      "102        5883           5883.0         0.0\n",
      "103        5898           5898.0         0.0\n",
      "104        5913           5913.0         0.0\n",
      "105        5928           5928.0         0.0\n",
      "106        5943           5943.0         0.0\n",
      "107        5958           5958.0         0.0\n",
      "108        5973           5973.0         0.0\n",
      "109        5988           5988.0         0.0\n"
     ]
    }
   ],
   "source": [
    "sequence = np.arange(4353, 6000, 15)\n",
    "predict_y = predict(sequence, best_model)\n",
    "mse = mean_squared_error(sequence, predict_y)\n",
    "print(f'mse is {mse}')\n",
    "plot_difference(sequence, predict_y, min_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBVn82yvdeqn"
   },
   "source": [
    "# **Prediction of geometric progression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szCruk54bD0-"
   },
   "source": [
    "$ b_n = b_1*q^{n-1}$  \n",
    "Пусть $q=2, b_1 = \\forall n \\in ${2, 3...100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_RzSmYoeySL"
   },
   "source": [
    "## **Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfTy9JsqstR0"
   },
   "outputs": [],
   "source": [
    "def generate_geometric_progression(start=1, num=15, d=1.5):\n",
    "    x = [start]\n",
    "    i = 1\n",
    "    while i < num:\n",
    "        next_value = x[-1] * d\n",
    "        x.append(next_value)\n",
    "        i += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxEuBpQid5Ff"
   },
   "outputs": [],
   "source": [
    "def generate_data(n_steps=3):\n",
    "  \n",
    "    batch_size = 3000\n",
    "    i = 0\n",
    "    num = 20\n",
    "    \n",
    "    X = np.empty((batch_size, n_steps))\n",
    "    y = np.empty((batch_size, 1))\n",
    "\n",
    "    start_val = 2\n",
    "\n",
    "    while i < batch_size:\n",
    "\n",
    "        array = generate_geometric_progression(start_val, num, 2)\n",
    "        j = 0\n",
    "\n",
    "        while j <= num - (n_steps + 1):\n",
    "            if i >= batch_size: \n",
    "                break\n",
    "            X[i, :] = array[j:n_steps+j]\n",
    "            y[i, :] = array[j+n_steps:j+n_steps + 1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "\n",
    "        start_val += 0.5\n",
    "            \n",
    "    _, index = np.unique(X, axis=0, return_index=True)\n",
    "    X, y = X[index], y[index]\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "qaAdSzGpnkqQ",
    "outputId": "e907811b-115a-48eb-d0e2-22f10822a8cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (1620, 4, 1)\n",
      "y_train shape is (1620, 1)\n"
     ]
    }
   ],
   "source": [
    "n_steps = 4\n",
    "X_train, y_train = generate_data(n_steps)\n",
    "print(f'X_train shape is {X_train.shape}')\n",
    "print(f'y_train shape is {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0SUQGjb9AuDT",
    "outputId": "38624f1d-791c-4f92-b2c9-a85f6d51ddd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 49807360.0)"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.min(X_train), np.max(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ij8Yxh2idzEi"
   },
   "source": [
    "# **Training model with one LSTM layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aM04sNYUxpw0"
   },
   "outputs": [],
   "source": [
    "def predict(true_sequence, model):\n",
    "    predict_values = true_sequence[:n_steps]\n",
    "    k = n_steps\n",
    "    length = true_sequence.size\n",
    "    while k != length:\n",
    "        X = predict_values[-n_steps::]\n",
    "        X = X.reshape((1, n_steps, 1))\n",
    "        f_x = model.predict(X, verbose=0)\n",
    "        predict_values = np.append(predict_values, f_x)\n",
    "        k += 1\n",
    "    return predict_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16BSC-SuxsHw"
   },
   "outputs": [],
   "source": [
    "def generate_test_values(start=1, num=15, d=1.5):\n",
    "\n",
    "    x = [start]\n",
    "    i = 1\n",
    "    \n",
    "    while i < num:\n",
    "        next_value = x[-1] * d\n",
    "        x.append(next_value)\n",
    "        i += 1\n",
    "\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3yLVOFyxuZd"
   },
   "outputs": [],
   "source": [
    "sequence = generate_test_values(15, 20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QpPyNI2Fxjdy",
    "outputId": "f17748d9-4a66-4c75-864f-b751cb80659c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units in LSTM layer: 1, MSE is: 4123119829495.569\n",
      "Units in LSTM layer: 2, MSE is: 313575725.1965\n",
      "Units in LSTM layer: 3, MSE is: 362783.4555\n",
      "Prediction of model with 3:\n",
      "    real value  predicted value  difference\n",
      "0           15           15.000         0.0\n",
      "1           30           30.000         0.0\n",
      "2           60           60.000         0.0\n",
      "3          120          120.000         0.0\n",
      "4          240          239.701         0.3\n",
      "5          480          479.099         0.9\n",
      "6          960          959.478         0.5\n",
      "7         1920         1921.092         1.1\n",
      "8         3840         3840.606         0.6\n",
      "9         7680         7680.577         0.6\n",
      "10       15360        15364.010         4.0\n",
      "11       30720        30730.664        10.7\n",
      "12       61440        61457.016        17.0\n",
      "13      122880       122913.609        33.6\n",
      "14      245760       245833.406        73.4\n",
      "15      491520       491668.938       148.9\n",
      "16      983040       983328.125       288.1\n",
      "17     1966080      1966658.000       578.0\n",
      "18     3932160      3933328.000      1168.0\n",
      "19     7864320      7866653.500      2333.5\n",
      "Units in LSTM layer: 4, MSE is: 3022581.2196\n",
      "Units in LSTM layer: 5, MSE is: 47983879.2735\n",
      "Units in LSTM layer: 6, MSE is: 4123086634587.6904\n",
      "Units in LSTM layer: 7, MSE is: 252148416.1688\n",
      "Prediction of model with 7:\n",
      "    real value  predicted value  difference\n",
      "0           15           15.000         0.0\n",
      "1           30           30.000         0.0\n",
      "2           60           60.000         0.0\n",
      "3          120          120.000         0.0\n",
      "4          240          239.989         0.0\n",
      "5          480          479.885         0.1\n",
      "6          960          960.191         0.2\n",
      "7         1920         1926.714         6.7\n",
      "8         3840         3852.477        12.5\n",
      "9         7680         7707.028        27.0\n",
      "10       15360        15423.160        63.2\n",
      "11       30720        30865.512       145.5\n",
      "12       61440        61748.883       308.9\n",
      "13      122880       123548.680       668.7\n",
      "14      245760       247206.812      1446.8\n",
      "15      491520       494620.625      3100.6\n",
      "16      983040       989632.500      6592.5\n",
      "17     1966080      1980084.875     14004.9\n",
      "18     3932160      3961809.500     29649.5\n",
      "19     7864320      7926866.000     62546.0\n",
      "Units in LSTM layer: 8, MSE is: 95485660.0338\n",
      "Units in LSTM layer: 9, MSE is: 1884813.1937\n",
      "Units in LSTM layer: 10, MSE is: 355378.7011\n",
      "Prediction of model with 10:\n",
      "    real value  predicted value  difference\n",
      "0           15           15.000         0.0\n",
      "1           30           30.000         0.0\n",
      "2           60           60.000         0.0\n",
      "3          120          120.000         0.0\n",
      "4          240          239.771         0.2\n",
      "5          480          479.890         0.1\n",
      "6          960          959.115         0.9\n",
      "7         1920         1918.841         1.2\n",
      "8         3840         3839.312         0.7\n",
      "9         7680         7677.323         2.7\n",
      "10       15360        15353.612         6.4\n",
      "11       30720        30710.203         9.8\n",
      "12       61440        61421.961        18.0\n",
      "13      122880       122839.469        40.5\n",
      "14      245760       245681.109        78.9\n",
      "15      491520       491371.281       148.7\n",
      "16      983040       982742.312       297.7\n",
      "17     1966080      1965482.750       597.2\n",
      "18     3932160      3930992.750      1167.2\n",
      "19     7864320      7862024.500      2295.5\n",
      "Units in LSTM layer: 15, MSE is: 5477116.6937\n",
      "Prediction of model with 15:\n",
      "    real value  predicted value  difference\n",
      "0           15           15.000         0.0\n",
      "1           30           30.000         0.0\n",
      "2           60           60.000         0.0\n",
      "3          120          120.000         0.0\n",
      "4          240          240.047         0.0\n",
      "5          480          480.204         0.2\n",
      "6          960          960.101         0.1\n",
      "7         1920         1917.195         2.8\n",
      "8         3840         3846.355         6.4\n",
      "9         7680         7688.411         8.4\n",
      "10       15360        15373.696        13.7\n",
      "11       30720        30747.725        27.7\n",
      "12       61440        61515.699        75.7\n",
      "13      122880       123015.359       135.4\n",
      "14      245760       246027.812       267.8\n",
      "15      491520       492070.438       550.4\n",
      "16      983040       984173.125      1133.1\n",
      "17     1966080      1968314.750      2234.8\n",
      "18     3932160      3936660.500      4500.5\n",
      "19     7864320      7873409.000      9089.0\n",
      "Units in LSTM layer: 20, MSE is: 583991.6909\n",
      "Units in LSTM layer: 25, MSE is: 1376937.1886\n",
      "Units in LSTM layer: 30, MSE is: 1476235.0547\n",
      "Prediction of model with 30:\n",
      "    real value  predicted value  difference\n",
      "0           15           15.000         0.0\n",
      "1           30           30.000         0.0\n",
      "2           60           60.000         0.0\n",
      "3          120          120.000         0.0\n",
      "4          240          239.751         0.2\n",
      "5          480          480.128         0.1\n",
      "6          960          958.598         1.4\n",
      "7         1920         1918.629         1.4\n",
      "8         3840         3837.864         2.1\n",
      "9         7680         7674.624         5.4\n",
      "10       15360        15349.398        10.6\n",
      "11       30720        30700.656        19.3\n",
      "12       61440        61400.727        39.3\n",
      "13      122880       122801.438        78.6\n",
      "14      245760       245606.047       154.0\n",
      "15      491520       491215.250       304.8\n",
      "16      983040       982434.875       605.1\n",
      "17     1966080      1964883.125      1196.9\n",
      "18     3932160      3929791.500      2368.5\n",
      "19     7864320      7859630.500      4689.5\n",
      "Units in LSTM layer: 35, MSE is: 340533.3404\n",
      "Units in LSTM layer: 40, MSE is: 997637.8277\n",
      "Prediction of model with 40:\n",
      "    real value  predicted value  difference\n",
      "0           15           15.000         0.0\n",
      "1           30           30.000         0.0\n",
      "2           60           60.000         0.0\n",
      "3          120          120.000         0.0\n",
      "4          240          240.264         0.3\n",
      "5          480          480.172         0.2\n",
      "6          960          959.611         0.4\n",
      "7         1920         1921.857         1.9\n",
      "8         3840         3843.124         3.1\n",
      "9         7680         7683.571         3.6\n",
      "10       15360        15367.209         7.2\n",
      "11       30720        30734.033        14.0\n",
      "12       61440        61457.066        17.1\n",
      "13      122880       122899.633        19.6\n",
      "14      245760       245776.234        16.2\n",
      "15      491520       491493.562        26.4\n",
      "16      983040       982865.688       174.3\n",
      "17     1966080      1965508.625       571.4\n",
      "18     3932160      3930562.000      1598.0\n",
      "19     7864320      7860192.000      4128.0\n",
      "Units in LSTM layer: 45, MSE is: 2311081.0372\n",
      "Units in LSTM layer: 50, MSE is: 180578.725\n",
      "Units in LSTM layer: 55, MSE is: 2158145.732\n",
      "Units in LSTM layer: 60, MSE is: 228359.4246\n",
      "Prediction of model with 60:\n",
      "    real value  predicted value  difference\n",
      "0           15           15.000         0.0\n",
      "1           30           30.000         0.0\n",
      "2           60           60.000         0.0\n",
      "3          120          120.000         0.0\n",
      "4          240          239.944         0.1\n",
      "5          480          480.003         0.0\n",
      "6          960          959.886         0.1\n",
      "7         1920         1920.673         0.7\n",
      "8         3840         3839.886         0.1\n",
      "9         7680         7680.913         0.9\n",
      "10       15360        15363.499         3.5\n",
      "11       30720        30727.488         7.5\n",
      "12       61440        61452.562        12.6\n",
      "13      122880       122908.539        28.5\n",
      "14      245760       245818.594        58.6\n",
      "15      491520       491635.156       115.2\n",
      "16      983040       983268.750       228.8\n",
      "17     1966080      1966544.500       464.5\n",
      "18     3932160      3933086.750       926.8\n",
      "19     7864320      7866170.000      1850.0\n"
     ]
    }
   ],
   "source": [
    "units_number = list(range(1, 11)) + list(range(15, 65, 5))\n",
    "losses = []\n",
    "min_loss = None\n",
    "min_unit = None\n",
    "\n",
    "for unit in units_number: \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(unit, activation='softplus', input_shape=(n_steps, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=800, validation_split=0.2, verbose=0)\n",
    "\n",
    "    predict_y = predict(sequence, model)\n",
    "    mse = mean_squared_error(sequence, predict_y)\n",
    "    if min_loss is None or mse < min_loss:\n",
    "         min_unit = unit\n",
    "         min_loss = mse\n",
    "         best_model = model\n",
    "    losses.append(mse)\n",
    "    \n",
    "    print(f'Units in LSTM layer: {unit}, MSE is: {np.round(mse, 4)}')\n",
    "    if unit in (3, 7, 10, 15, 30, 40, 60):\n",
    "        plot_difference(sequence, predict_y, unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "id": "ee0-S-HONx5N",
    "outputId": "92432474-6d63-43ac-d6f9-95f364d2d230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse is 2042.6830888683703\n",
      "Prediction of model with 50:\n",
      "    real value  predicted value  difference\n",
      "0            5            5.000         0.0\n",
      "1           10           10.000         0.0\n",
      "2           20           20.000         0.0\n",
      "3           40           40.000         0.0\n",
      "4           80           80.019         0.0\n",
      "5          160          160.011         0.0\n",
      "6          320          320.164         0.2\n",
      "7          640          640.187         0.2\n",
      "8         1280         1280.764         0.8\n",
      "9         2560         2561.523         1.5\n",
      "10        5120         5119.422         0.6\n",
      "11       10240        10240.070         0.1\n",
      "12       20480        20479.809         0.2\n",
      "13       40960        40958.086         1.9\n",
      "14       81920        81914.430         5.6\n",
      "15      163840       163830.125         9.9\n",
      "16      327680       327658.750        21.2\n",
      "17      655360       655316.188        43.8\n",
      "18     1310720      1310632.125        87.9\n",
      "19     2621440      2621265.000       175.0\n"
     ]
    }
   ],
   "source": [
    "sequence = generate_test_values(5, 20, 2)\n",
    "predict_y = predict(sequence, best_model)\n",
    "mse = mean_squared_error(sequence, predict_y)\n",
    "print(f'mse is {mse}')\n",
    "plot_difference(sequence, predict_y, min_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "id": "gzeRMtwrREbi",
    "outputId": "feb04c51-e089-4cf5-d276-d0fb6b3a8ad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse is 59895.720104568274\n",
      "Prediction of model with 50:\n",
      "    real value  predicted value  difference\n",
      "0           10           10.000         0.0\n",
      "1           20           20.000         0.0\n",
      "2           40           40.000         0.0\n",
      "3           80           80.000         0.0\n",
      "4          160          159.997         0.0\n",
      "5          320          320.128         0.1\n",
      "6          640          640.114         0.1\n",
      "7         1280         1280.614         0.6\n",
      "8         2560         2561.237         1.2\n",
      "9         5120         5118.838         1.2\n",
      "10       10240        10238.904         1.1\n",
      "11       20480        20477.479         2.5\n",
      "12       40960        40953.434         6.6\n",
      "13       81920        81905.109        14.9\n",
      "14      163840       163811.469        28.5\n",
      "15      327680       327621.469        58.5\n",
      "16      655360       655241.562       118.4\n",
      "17     1310720      1310482.875       237.1\n",
      "18     2621440      2620966.250       473.8\n",
      "19     5242880      5241932.000       948.0\n"
     ]
    }
   ],
   "source": [
    "sequence = generate_test_values(10, 20, 2)\n",
    "predict_y = predict(sequence, best_model)\n",
    "mse = mean_squared_error(sequence, predict_y)\n",
    "print(f'mse is {mse}')\n",
    "plot_difference(sequence, predict_y, min_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tICdqHvRGnY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Recurrence relations (p=1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
