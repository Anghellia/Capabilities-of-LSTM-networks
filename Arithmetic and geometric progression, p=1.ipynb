{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6303,
     "status": "ok",
     "timestamp": 1588944680275,
     "user": {
      "displayName": "Анжелла Панкратова",
      "photoUrl": "https://lh6.googleusercontent.com/-hkI5RCmUZFM/AAAAAAAAAAI/AAAAAAAAADg/sJvW0KD7Luw/s64/photo.jpg",
      "userId": "10606067150129738728"
     },
     "user_tz": -180
    },
    "id": "wKxPT9OtU0S-",
    "outputId": "f371dccb-bace-4b8c-f6a6-4614ff61bbcf"
   },
   "outputs": [],
   "source": [
    "# Импортируем библиотеки\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PD4wPEz2UAem"
   },
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps):\n",
    "    n = len(sequence)\n",
    "    X, y = list(), list()\n",
    "    for i in range(n):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > n-1:\n",
    "            break\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocHq9qOIuTzO"
   },
   "outputs": [],
   "source": [
    "def plot_difference(true_sequence, predict_values, unit):\n",
    "    print(f'Prediction of model with {unit}:')\n",
    "    df = pd.DataFrame({'real value': true_sequence, 'predicted value': np.round(predict_values, 3), 'difference': np.round(abs(true_sequence-predict_values), 1)})\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NeKFWpves9I"
   },
   "source": [
    "# **Prediction of arithmetic progression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RpjI5ZIXTjNj"
   },
   "source": [
    "$a_n = a_1 + (n-1)*d$  \n",
    "\n",
    "Пусть $d=15$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-Bdby3aTjgB"
   },
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TtenYsCELEp_"
   },
   "outputs": [],
   "source": [
    "def generate_arithmetic_progression(n_steps=4, d=15): # d - шаг арифметической прогрессии\n",
    "\n",
    "    num = 700\n",
    "    batch_size = 2000\n",
    "    i = 0\n",
    "    \n",
    "    X = np.empty((batch_size, n_steps))\n",
    "    y = np.empty((batch_size, 1))\n",
    "\n",
    "    start_val = 10\n",
    "\n",
    "    while i < batch_size:\n",
    "    \n",
    "        array =  np.arange(start_val, start_val +(num-1)*d + 1, d)\n",
    "        j = 0\n",
    "\n",
    "        while j <= num - (n_steps + 1):\n",
    "            if i >= batch_size: break\n",
    "            X[i, :] = array[j:n_steps+j]\n",
    "            y[i, :] = array[j+n_steps]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        \n",
    "        start_val -= 1\n",
    "\n",
    "    _, index = np.unique(X, axis=0, return_index=True)\n",
    "    X, y = X[index], y[index]\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQ_s5Sn6MrYm"
   },
   "outputs": [],
   "source": [
    "n_steps = 4\n",
    "X_train, y_train = generate_arithmetic_progression(n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1268,
     "status": "ok",
     "timestamp": 1588926127578,
     "user": {
      "displayName": "Анжелла Панкратова",
      "photoUrl": "https://lh6.googleusercontent.com/-hkI5RCmUZFM/AAAAAAAAAAI/AAAAAAAAADg/sJvW0KD7Luw/s64/photo.jpg",
      "userId": "10606067150129738728"
     },
     "user_tz": -180
    },
    "id": "CEm205SMo0xq",
    "outputId": "1720897b-db7f-4b42-f231-f39adaa92d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (2000, 4, 1)\n",
      "y_train shape is (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape is {X_train.shape}')\n",
    "print(f'y_train shape is {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sDitZDYadLe"
   },
   "source": [
    "## **Training model with one LSTM layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smHDKs5EAHLa"
   },
   "outputs": [],
   "source": [
    "def predict(true_sequence, model):\n",
    "    predict_values = true_sequence[:n_steps]\n",
    "    k = n_steps\n",
    "    length = true_sequence.size\n",
    "    while k != length:\n",
    "        X = predict_values[-n_steps::]\n",
    "        X = X.reshape((1, n_steps, 1))\n",
    "        f_x = np.round(model.predict(X, verbose=0))\n",
    "        predict_values = np.append(predict_values, f_x)\n",
    "        k += 1\n",
    "    return predict_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6Odj8IwAIzK"
   },
   "outputs": [],
   "source": [
    "sequence = np.arange(8111, 9000, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1564402,
     "status": "ok",
     "timestamp": 1588927784661,
     "user": {
      "displayName": "Анжелла Панкратова",
      "photoUrl": "https://lh6.googleusercontent.com/-hkI5RCmUZFM/AAAAAAAAAAI/AAAAAAAAADg/sJvW0KD7Luw/s64/photo.jpg",
      "userId": "10606067150129738728"
     },
     "user_tz": -180
    },
    "id": "3XT0T7hxqm2z",
    "outputId": "5b3e7f78-3c4c-4701-bdbc-fa17b0533bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units in LSTM layer: 1, MSE is: 68403615.0\n",
      "Prediction of model with 1:\n",
      "    real value  predicted value  difference\n",
      "0         8111           8111.0         0.0\n",
      "1         8126           8126.0         0.0\n",
      "2         8141           8141.0         0.0\n",
      "3         8156           8156.0         0.0\n",
      "4         8171             26.0      8145.0\n",
      "5         8186             26.0      8160.0\n",
      "6         8201             26.0      8175.0\n",
      "7         8216             26.0      8190.0\n",
      "8         8231             26.0      8205.0\n",
      "9         8246             26.0      8220.0\n",
      "10        8261             26.0      8235.0\n",
      "11        8276             26.0      8250.0\n",
      "12        8291             26.0      8265.0\n",
      "13        8306             26.0      8280.0\n",
      "14        8321             26.0      8295.0\n",
      "15        8336             26.0      8310.0\n",
      "16        8351             26.0      8325.0\n",
      "17        8366             26.0      8340.0\n",
      "18        8381             26.0      8355.0\n",
      "19        8396             26.0      8370.0\n",
      "20        8411             26.0      8385.0\n",
      "21        8426             26.0      8400.0\n",
      "22        8441             26.0      8415.0\n",
      "23        8456             26.0      8430.0\n",
      "24        8471             26.0      8445.0\n",
      "25        8486             26.0      8460.0\n",
      "26        8501             26.0      8475.0\n",
      "27        8516             26.0      8490.0\n",
      "28        8531             26.0      8505.0\n",
      "29        8546             26.0      8520.0\n",
      "30        8561             26.0      8535.0\n",
      "31        8576             26.0      8550.0\n",
      "32        8591             26.0      8565.0\n",
      "33        8606             26.0      8580.0\n",
      "34        8621             26.0      8595.0\n",
      "35        8636             26.0      8610.0\n",
      "36        8651             26.0      8625.0\n",
      "37        8666             26.0      8640.0\n",
      "38        8681             26.0      8655.0\n",
      "39        8696             26.0      8670.0\n",
      "40        8711             26.0      8685.0\n",
      "41        8726             26.0      8700.0\n",
      "42        8741             26.0      8715.0\n",
      "43        8756             26.0      8730.0\n",
      "44        8771             26.0      8745.0\n",
      "45        8786             26.0      8760.0\n",
      "46        8801             26.0      8775.0\n",
      "47        8816             26.0      8790.0\n",
      "48        8831             26.0      8805.0\n",
      "49        8846             26.0      8820.0\n",
      "50        8861             26.0      8835.0\n",
      "51        8876             26.0      8850.0\n",
      "52        8891             26.0      8865.0\n",
      "53        8906             26.0      8880.0\n",
      "54        8921             26.0      8895.0\n",
      "55        8936             26.0      8910.0\n",
      "56        8951             26.0      8925.0\n",
      "57        8966             26.0      8940.0\n",
      "58        8981             26.0      8955.0\n",
      "59        8996             26.0      8970.0\n",
      "Units in LSTM layer: 2, MSE is: 68419589.9333\n",
      "Units in LSTM layer: 3, MSE is: 10630.55\n",
      "Units in LSTM layer: 4, MSE is: 14221.0\n",
      "Units in LSTM layer: 5, MSE is: 68387913.4167\n",
      "Units in LSTM layer: 6, MSE is: 8423.05\n",
      "Units in LSTM layer: 7, MSE is: 1094.1167\n",
      "Units in LSTM layer: 8, MSE is: 0.0\n",
      "Units in LSTM layer: 9, MSE is: 0.0\n",
      "Units in LSTM layer: 10, MSE is: 0.0\n",
      "Prediction of model with 10:\n",
      "    real value  predicted value  difference\n",
      "0         8111           8111.0         0.0\n",
      "1         8126           8126.0         0.0\n",
      "2         8141           8141.0         0.0\n",
      "3         8156           8156.0         0.0\n",
      "4         8171           8171.0         0.0\n",
      "5         8186           8186.0         0.0\n",
      "6         8201           8201.0         0.0\n",
      "7         8216           8216.0         0.0\n",
      "8         8231           8231.0         0.0\n",
      "9         8246           8246.0         0.0\n",
      "10        8261           8261.0         0.0\n",
      "11        8276           8276.0         0.0\n",
      "12        8291           8291.0         0.0\n",
      "13        8306           8306.0         0.0\n",
      "14        8321           8321.0         0.0\n",
      "15        8336           8336.0         0.0\n",
      "16        8351           8351.0         0.0\n",
      "17        8366           8366.0         0.0\n",
      "18        8381           8381.0         0.0\n",
      "19        8396           8396.0         0.0\n",
      "20        8411           8411.0         0.0\n",
      "21        8426           8426.0         0.0\n",
      "22        8441           8441.0         0.0\n",
      "23        8456           8456.0         0.0\n",
      "24        8471           8471.0         0.0\n",
      "25        8486           8486.0         0.0\n",
      "26        8501           8501.0         0.0\n",
      "27        8516           8516.0         0.0\n",
      "28        8531           8531.0         0.0\n",
      "29        8546           8546.0         0.0\n",
      "30        8561           8561.0         0.0\n",
      "31        8576           8576.0         0.0\n",
      "32        8591           8591.0         0.0\n",
      "33        8606           8606.0         0.0\n",
      "34        8621           8621.0         0.0\n",
      "35        8636           8636.0         0.0\n",
      "36        8651           8651.0         0.0\n",
      "37        8666           8666.0         0.0\n",
      "38        8681           8681.0         0.0\n",
      "39        8696           8696.0         0.0\n",
      "40        8711           8711.0         0.0\n",
      "41        8726           8726.0         0.0\n",
      "42        8741           8741.0         0.0\n",
      "43        8756           8756.0         0.0\n",
      "44        8771           8771.0         0.0\n",
      "45        8786           8786.0         0.0\n",
      "46        8801           8801.0         0.0\n",
      "47        8816           8816.0         0.0\n",
      "48        8831           8831.0         0.0\n",
      "49        8846           8846.0         0.0\n",
      "50        8861           8861.0         0.0\n",
      "51        8876           8876.0         0.0\n",
      "52        8891           8891.0         0.0\n",
      "53        8906           8906.0         0.0\n",
      "54        8921           8921.0         0.0\n",
      "55        8936           8936.0         0.0\n",
      "56        8951           8951.0         0.0\n",
      "57        8966           8966.0         0.0\n",
      "58        8981           8981.0         0.0\n",
      "59        8996           8996.0         0.0\n",
      "Units in LSTM layer: 15, MSE is: 521940.8667\n",
      "Units in LSTM layer: 20, MSE is: 19293.45\n",
      "Prediction of model with 20:\n",
      "    real value  predicted value  difference\n",
      "0         8111           8111.0         0.0\n",
      "1         8126           8126.0         0.0\n",
      "2         8141           8141.0         0.0\n",
      "3         8156           8156.0         0.0\n",
      "4         8171           8178.0         7.0\n",
      "5         8186           8194.0         8.0\n",
      "6         8201           8213.0        12.0\n",
      "7         8216           8234.0        18.0\n",
      "8         8231           8250.0        19.0\n",
      "9         8246           8271.0        25.0\n",
      "10        8261           8290.0        29.0\n",
      "11        8276           8307.0        31.0\n",
      "12        8291           8329.0        38.0\n",
      "13        8306           8346.0        40.0\n",
      "14        8321           8365.0        44.0\n",
      "15        8336           8386.0        50.0\n",
      "16        8351           8403.0        52.0\n",
      "17        8366           8423.0        57.0\n",
      "18        8381           8443.0        62.0\n",
      "19        8396           8460.0        64.0\n",
      "20        8411           8481.0        70.0\n",
      "21        8426           8500.0        74.0\n",
      "22        8441           8518.0        77.0\n",
      "23        8456           8539.0        83.0\n",
      "24        8471           8557.0        86.0\n",
      "25        8486           8577.0        91.0\n",
      "26        8501           8597.0        96.0\n",
      "27        8516           8615.0        99.0\n",
      "28        8531           8636.0       105.0\n",
      "29        8546           8655.0       109.0\n",
      "30        8561           8674.0       113.0\n",
      "31        8576           8695.0       119.0\n",
      "32        8591           8713.0       122.0\n",
      "33        8606           8733.0       127.0\n",
      "34        8621           8753.0       132.0\n",
      "35        8636           8772.0       136.0\n",
      "36        8651           8792.0       141.0\n",
      "37        8666           8812.0       146.0\n",
      "38        8681           8831.0       150.0\n",
      "39        8696           8851.0       155.0\n",
      "40        8711           8871.0       160.0\n",
      "41        8726           8890.0       164.0\n",
      "42        8741           8911.0       170.0\n",
      "43        8756           8930.0       174.0\n",
      "44        8771           8950.0       179.0\n",
      "45        8786           8970.0       184.0\n",
      "46        8801           8989.0       188.0\n",
      "47        8816           9010.0       194.0\n",
      "48        8831           9029.0       198.0\n",
      "49        8846           9049.0       203.0\n",
      "50        8861           9070.0       209.0\n",
      "51        8876           9089.0       213.0\n",
      "52        8891           9110.0       219.0\n",
      "53        8906           9130.0       224.0\n",
      "54        8921           9150.0       229.0\n",
      "55        8936           9171.0       235.0\n",
      "56        8951           9190.0       239.0\n",
      "57        8966           9211.0       245.0\n",
      "58        8981           9231.0       250.0\n",
      "59        8996           9251.0       255.0\n",
      "Units in LSTM layer: 25, MSE is: 0.0\n",
      "Units in LSTM layer: 30, MSE is: 1056.15\n",
      "Units in LSTM layer: 35, MSE is: 0.0\n",
      "Units in LSTM layer: 40, MSE is: 0.0\n",
      "Prediction of model with 40:\n",
      "    real value  predicted value  difference\n",
      "0         8111           8111.0         0.0\n",
      "1         8126           8126.0         0.0\n",
      "2         8141           8141.0         0.0\n",
      "3         8156           8156.0         0.0\n",
      "4         8171           8171.0         0.0\n",
      "5         8186           8186.0         0.0\n",
      "6         8201           8201.0         0.0\n",
      "7         8216           8216.0         0.0\n",
      "8         8231           8231.0         0.0\n",
      "9         8246           8246.0         0.0\n",
      "10        8261           8261.0         0.0\n",
      "11        8276           8276.0         0.0\n",
      "12        8291           8291.0         0.0\n",
      "13        8306           8306.0         0.0\n",
      "14        8321           8321.0         0.0\n",
      "15        8336           8336.0         0.0\n",
      "16        8351           8351.0         0.0\n",
      "17        8366           8366.0         0.0\n",
      "18        8381           8381.0         0.0\n",
      "19        8396           8396.0         0.0\n",
      "20        8411           8411.0         0.0\n",
      "21        8426           8426.0         0.0\n",
      "22        8441           8441.0         0.0\n",
      "23        8456           8456.0         0.0\n",
      "24        8471           8471.0         0.0\n",
      "25        8486           8486.0         0.0\n",
      "26        8501           8501.0         0.0\n",
      "27        8516           8516.0         0.0\n",
      "28        8531           8531.0         0.0\n",
      "29        8546           8546.0         0.0\n",
      "30        8561           8561.0         0.0\n",
      "31        8576           8576.0         0.0\n",
      "32        8591           8591.0         0.0\n",
      "33        8606           8606.0         0.0\n",
      "34        8621           8621.0         0.0\n",
      "35        8636           8636.0         0.0\n",
      "36        8651           8651.0         0.0\n",
      "37        8666           8666.0         0.0\n",
      "38        8681           8681.0         0.0\n",
      "39        8696           8696.0         0.0\n",
      "40        8711           8711.0         0.0\n",
      "41        8726           8726.0         0.0\n",
      "42        8741           8741.0         0.0\n",
      "43        8756           8756.0         0.0\n",
      "44        8771           8771.0         0.0\n",
      "45        8786           8786.0         0.0\n",
      "46        8801           8801.0         0.0\n",
      "47        8816           8816.0         0.0\n",
      "48        8831           8831.0         0.0\n",
      "49        8846           8846.0         0.0\n",
      "50        8861           8861.0         0.0\n",
      "51        8876           8876.0         0.0\n",
      "52        8891           8891.0         0.0\n",
      "53        8906           8906.0         0.0\n",
      "54        8921           8921.0         0.0\n",
      "55        8936           8936.0         0.0\n",
      "56        8951           8951.0         0.0\n",
      "57        8966           8966.0         0.0\n",
      "58        8981           8981.0         0.0\n",
      "59        8996           8996.0         0.0\n",
      "Units in LSTM layer: 45, MSE is: 1002.3333\n",
      "Units in LSTM layer: 50, MSE is: 81.95\n",
      "Units in LSTM layer: 55, MSE is: 0.0\n",
      "Units in LSTM layer: 60, MSE is: 0.0\n"
     ]
    }
   ],
   "source": [
    "units_number = list(range(1, 11)) + list(range(15, 65, 5))\n",
    "losses = []\n",
    "min_loss = None\n",
    "min_unit = None\n",
    "\n",
    "for unit in units_number: \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(unit, activation='softplus', input_shape=(n_steps, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=300, validation_split=0.2, verbose=0)\n",
    "\n",
    "    predict_y = predict(sequence, model)\n",
    "    mse = mean_squared_error(sequence, predict_y)\n",
    "\n",
    "    if min_loss is None or mse < min_loss:\n",
    "        min_unit = unit\n",
    "        min_loss = mse\n",
    "        best_model = model\n",
    "    losses.append(mse)\n",
    "    \n",
    "    print(f'Units in LSTM layer: {unit}, MSE is: {np.round(mse, 4)}')\n",
    "    if unit in (1, 10, 20, 40):\n",
    "        plot_difference(sequence, predict_y, unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1558092,
     "status": "ok",
     "timestamp": 1588927784664,
     "user": {
      "displayName": "Анжелла Панкратова",
      "photoUrl": "https://lh6.googleusercontent.com/-hkI5RCmUZFM/AAAAAAAAAAI/AAAAAAAAADg/sJvW0KD7Luw/s64/photo.jpg",
      "userId": "10606067150129738728"
     },
     "user_tz": -180
    },
    "id": "AXHmd4e1vSiS",
    "outputId": "7793fcf2-3599-40b7-cd31-f8cff5823230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse is 0.0\n",
      "Prediction of model with 8:\n",
      "     real value  predicted value  difference\n",
      "0          4353           4353.0         0.0\n",
      "1          4368           4368.0         0.0\n",
      "2          4383           4383.0         0.0\n",
      "3          4398           4398.0         0.0\n",
      "4          4413           4413.0         0.0\n",
      "5          4428           4428.0         0.0\n",
      "6          4443           4443.0         0.0\n",
      "7          4458           4458.0         0.0\n",
      "8          4473           4473.0         0.0\n",
      "9          4488           4488.0         0.0\n",
      "10         4503           4503.0         0.0\n",
      "11         4518           4518.0         0.0\n",
      "12         4533           4533.0         0.0\n",
      "13         4548           4548.0         0.0\n",
      "14         4563           4563.0         0.0\n",
      "15         4578           4578.0         0.0\n",
      "16         4593           4593.0         0.0\n",
      "17         4608           4608.0         0.0\n",
      "18         4623           4623.0         0.0\n",
      "19         4638           4638.0         0.0\n",
      "20         4653           4653.0         0.0\n",
      "21         4668           4668.0         0.0\n",
      "22         4683           4683.0         0.0\n",
      "23         4698           4698.0         0.0\n",
      "24         4713           4713.0         0.0\n",
      "25         4728           4728.0         0.0\n",
      "26         4743           4743.0         0.0\n",
      "27         4758           4758.0         0.0\n",
      "28         4773           4773.0         0.0\n",
      "29         4788           4788.0         0.0\n",
      "30         4803           4803.0         0.0\n",
      "31         4818           4818.0         0.0\n",
      "32         4833           4833.0         0.0\n",
      "33         4848           4848.0         0.0\n",
      "34         4863           4863.0         0.0\n",
      "35         4878           4878.0         0.0\n",
      "36         4893           4893.0         0.0\n",
      "37         4908           4908.0         0.0\n",
      "38         4923           4923.0         0.0\n",
      "39         4938           4938.0         0.0\n",
      "40         4953           4953.0         0.0\n",
      "41         4968           4968.0         0.0\n",
      "42         4983           4983.0         0.0\n",
      "43         4998           4998.0         0.0\n",
      "44         5013           5013.0         0.0\n",
      "45         5028           5028.0         0.0\n",
      "46         5043           5043.0         0.0\n",
      "47         5058           5058.0         0.0\n",
      "48         5073           5073.0         0.0\n",
      "49         5088           5088.0         0.0\n",
      "50         5103           5103.0         0.0\n",
      "51         5118           5118.0         0.0\n",
      "52         5133           5133.0         0.0\n",
      "53         5148           5148.0         0.0\n",
      "54         5163           5163.0         0.0\n",
      "55         5178           5178.0         0.0\n",
      "56         5193           5193.0         0.0\n",
      "57         5208           5208.0         0.0\n",
      "58         5223           5223.0         0.0\n",
      "59         5238           5238.0         0.0\n",
      "60         5253           5253.0         0.0\n",
      "61         5268           5268.0         0.0\n",
      "62         5283           5283.0         0.0\n",
      "63         5298           5298.0         0.0\n",
      "64         5313           5313.0         0.0\n",
      "65         5328           5328.0         0.0\n",
      "66         5343           5343.0         0.0\n",
      "67         5358           5358.0         0.0\n",
      "68         5373           5373.0         0.0\n",
      "69         5388           5388.0         0.0\n",
      "70         5403           5403.0         0.0\n",
      "71         5418           5418.0         0.0\n",
      "72         5433           5433.0         0.0\n",
      "73         5448           5448.0         0.0\n",
      "74         5463           5463.0         0.0\n",
      "75         5478           5478.0         0.0\n",
      "76         5493           5493.0         0.0\n",
      "77         5508           5508.0         0.0\n",
      "78         5523           5523.0         0.0\n",
      "79         5538           5538.0         0.0\n",
      "80         5553           5553.0         0.0\n",
      "81         5568           5568.0         0.0\n",
      "82         5583           5583.0         0.0\n",
      "83         5598           5598.0         0.0\n",
      "84         5613           5613.0         0.0\n",
      "85         5628           5628.0         0.0\n",
      "86         5643           5643.0         0.0\n",
      "87         5658           5658.0         0.0\n",
      "88         5673           5673.0         0.0\n",
      "89         5688           5688.0         0.0\n",
      "90         5703           5703.0         0.0\n",
      "91         5718           5718.0         0.0\n",
      "92         5733           5733.0         0.0\n",
      "93         5748           5748.0         0.0\n",
      "94         5763           5763.0         0.0\n",
      "95         5778           5778.0         0.0\n",
      "96         5793           5793.0         0.0\n",
      "97         5808           5808.0         0.0\n",
      "98         5823           5823.0         0.0\n",
      "99         5838           5838.0         0.0\n",
      "100        5853           5853.0         0.0\n",
      "101        5868           5868.0         0.0\n",
      "102        5883           5883.0         0.0\n",
      "103        5898           5898.0         0.0\n",
      "104        5913           5913.0         0.0\n",
      "105        5928           5928.0         0.0\n",
      "106        5943           5943.0         0.0\n",
      "107        5958           5958.0         0.0\n",
      "108        5973           5973.0         0.0\n",
      "109        5988           5988.0         0.0\n"
     ]
    }
   ],
   "source": [
    "sequence = np.arange(4353, 6000, 15)\n",
    "predict_y = predict(sequence, best_model)\n",
    "mse = mean_squared_error(sequence, predict_y)\n",
    "print(f'mse is {mse}')\n",
    "plot_difference(sequence, predict_y, min_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBVn82yvdeqn"
   },
   "source": [
    "# **Prediction of geometric progression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szCruk54bD0-"
   },
   "source": [
    "$ b_n = b_1*q^{n-1}$  \n",
    "Пусть $q=2, b_1 = \\forall n \\in ${2, 3...100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_RzSmYoeySL"
   },
   "source": [
    "## **Data generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfTy9JsqstR0"
   },
   "outputs": [],
   "source": [
    "def generate_geometric_progression(start=1, num=15, d=1.5):\n",
    "    x = [start]\n",
    "    i = 1\n",
    "    while i < num:\n",
    "        next_value = x[-1] * d\n",
    "        x.append(next_value)\n",
    "        i += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxEuBpQid5Ff"
   },
   "outputs": [],
   "source": [
    "def generate_data(n_steps=3):\n",
    "  \n",
    "    batch_size = 3000\n",
    "    i = 0\n",
    "    num = 20\n",
    "    \n",
    "    X = np.empty((batch_size, n_steps))\n",
    "    y = np.empty((batch_size, 1))\n",
    "\n",
    "    start_val = 2\n",
    "\n",
    "    while i < batch_size:\n",
    "\n",
    "        array = generate_geometric_progression(start_val, num, 2)\n",
    "        j = 0\n",
    "\n",
    "        while j <= num - (n_steps + 1):\n",
    "            if i >= batch_size: \n",
    "                break\n",
    "            X[i, :] = array[j:n_steps+j]\n",
    "            y[i, :] = array[j+n_steps:j+n_steps + 1]\n",
    "            i += 1\n",
    "            j += 1\n",
    "\n",
    "        start_val += 2\n",
    "        print(start_val)\n",
    "\n",
    "    _, index = np.unique(X, axis=0, return_index=True)\n",
    "    X, y = X[index], y[index]\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 532,
     "status": "ok",
     "timestamp": 1588945244710,
     "user": {
      "displayName": "Анжелла Панкратова",
      "photoUrl": "https://lh6.googleusercontent.com/-hkI5RCmUZFM/AAAAAAAAAAI/AAAAAAAAADg/sJvW0KD7Luw/s64/photo.jpg",
      "userId": "10606067150129738728"
     },
     "user_tz": -180
    },
    "id": "qaAdSzGpnkqQ",
    "outputId": "81e3f3d3-4073-4766-d4b5-3647f8aa98b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape is (1090, 4, 1)\n",
      "y_train shape is (1090, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape is {X_train.shape}')\n",
    "print(f'y_train shape is {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ij8Yxh2idzEi"
   },
   "source": [
    "# **Training model with one LSTM layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aM04sNYUxpw0"
   },
   "outputs": [],
   "source": [
    "def predict(true_sequence, model):\n",
    "    predict_values = true_sequence[:n_steps]\n",
    "    k = n_steps\n",
    "    length = true_sequence.size\n",
    "    while k != length:\n",
    "        X = predict_values[-n_steps::]\n",
    "        X = X.reshape((1, n_steps, 1))\n",
    "        f_x = model.predict(X, verbose=0)\n",
    "        predict_values = np.append(predict_values, f_x)\n",
    "        k += 1\n",
    "    return predict_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16BSC-SuxsHw"
   },
   "outputs": [],
   "source": [
    "def generate_test_values(start=1, num=15, d=1.5):\n",
    "\n",
    "    x = [start]\n",
    "    i = 1\n",
    "    \n",
    "    while i < num:\n",
    "        next_value = x[-1] * d\n",
    "        x.append(next_value)\n",
    "        i += 1\n",
    "\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3yLVOFyxuZd"
   },
   "outputs": [],
   "source": [
    "sequence = generate_test_values(3, 23, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2577663,
     "status": "ok",
     "timestamp": 1588930362364,
     "user": {
      "displayName": "Анжелла Панкратова",
      "photoUrl": "https://lh6.googleusercontent.com/-hkI5RCmUZFM/AAAAAAAAAAI/AAAAAAAAADg/sJvW0KD7Luw/s64/photo.jpg",
      "userId": "10606067150129738728"
     },
     "user_tz": -180
    },
    "id": "QpPyNI2Fxjdy",
    "outputId": "6b64c796-90a9-42f2-e44b-89622cec8417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units in LSTM layer: 1, MSE is: 9178455169603.006\n",
      "Units in LSTM layer: 2, MSE is: 6047793066.8327\n",
      "Units in LSTM layer: 3, MSE is: 784242577.6989\n",
      "Prediction of model with 3:\n",
      "    real value  predicted value  difference\n",
      "0            3     3.000000e+00         0.0\n",
      "1            6     6.000000e+00         0.0\n",
      "2           12     1.200000e+01         0.0\n",
      "3           24     2.400000e+01         0.0\n",
      "4           48     4.718600e+01         0.8\n",
      "5           96     9.533000e+01         0.7\n",
      "6          192     1.850060e+02         7.0\n",
      "7          384     3.816900e+02         2.3\n",
      "8          768     7.669600e+02         1.0\n",
      "9         1536     1.526471e+03         9.5\n",
      "10        3072     3.016699e+03        55.3\n",
      "11        6144     6.098262e+03        45.7\n",
      "12       12288     1.219630e+04        91.7\n",
      "13       24576     2.435312e+04       222.9\n",
      "14       49152     4.862555e+04       526.5\n",
      "15       98304     9.744991e+04       854.1\n",
      "16      196608     1.948628e+05      1745.2\n",
      "17      393216     3.895741e+05      3641.9\n",
      "18      786432     7.789975e+05      7434.5\n",
      "19     1572864     1.558582e+06     14282.1\n",
      "20     3145728     3.116929e+06     28799.2\n",
      "21     6291456     6.233344e+06     58112.0\n",
      "22    12582912     1.246649e+07    116424.0\n",
      "Units in LSTM layer: 4, MSE is: 1776904941.0554\n",
      "Units in LSTM layer: 5, MSE is: 5893277386.8424\n",
      "Units in LSTM layer: 6, MSE is: 132743215.2519\n",
      "Units in LSTM layer: 7, MSE is: 2552300.7262\n",
      "Prediction of model with 7:\n",
      "    real value  predicted value  difference\n",
      "0            3     3.000000e+00         0.0\n",
      "1            6     6.000000e+00         0.0\n",
      "2           12     1.200000e+01         0.0\n",
      "3           24     2.400000e+01         0.0\n",
      "4           48     4.807300e+01         0.1\n",
      "5           96     9.610200e+01         0.1\n",
      "6          192     1.920310e+02         0.0\n",
      "7          384     3.842260e+02         0.2\n",
      "8          768     7.677490e+02         0.3\n",
      "9         1536     1.534917e+03         1.1\n",
      "10        3072     3.074476e+03         2.5\n",
      "11        6144     6.147739e+03         3.7\n",
      "12       12288     1.229315e+04         5.1\n",
      "13       24576     2.458706e+04        11.1\n",
      "14       49152     4.918152e+04        29.5\n",
      "15       98304     9.835784e+04        53.8\n",
      "16      196608     1.967108e+05       102.8\n",
      "17      393216     3.934259e+05       209.9\n",
      "18      786432     7.868603e+05       428.3\n",
      "19     1572864     1.573703e+06       838.8\n",
      "20     3145728     3.147392e+06      1663.8\n",
      "21     6291456     6.294782e+06      3325.5\n",
      "22    12582912     1.258954e+07      6628.0\n",
      "Units in LSTM layer: 8, MSE is: 19494323.1734\n",
      "Units in LSTM layer: 9, MSE is: 936896.3159\n",
      "Units in LSTM layer: 10, MSE is: 15391777.375\n",
      "Units in LSTM layer: 15, MSE is: 1811568.5298\n",
      "Prediction of model with 15:\n",
      "    real value  predicted value  difference\n",
      "0            3     3.000000e+00         0.0\n",
      "1            6     6.000000e+00         0.0\n",
      "2           12     1.200000e+01         0.0\n",
      "3           24     2.400000e+01         0.0\n",
      "4           48     4.796700e+01         0.0\n",
      "5           96     9.592300e+01         0.1\n",
      "6          192     1.918830e+02         0.1\n",
      "7          384     3.836930e+02         0.3\n",
      "8          768     7.683870e+02         0.4\n",
      "9         1536     1.535532e+03         0.5\n",
      "10        3072     3.073744e+03         1.7\n",
      "11        6144     6.146070e+03         2.1\n",
      "12       12288     1.229420e+04         6.2\n",
      "13       24576     2.458460e+04         8.6\n",
      "14       49152     4.917659e+04        24.6\n",
      "15       98304     9.834670e+04        42.7\n",
      "16      196608     1.966988e+05        90.8\n",
      "17      393216     3.933869e+05       170.9\n",
      "18      786432     7.867934e+05       361.4\n",
      "19     1572864     1.573561e+06       697.2\n",
      "20     3145728     3.147136e+06      1408.0\n",
      "21     6291456     6.294235e+06      2779.0\n",
      "22    12582912     1.258851e+07      5595.0\n",
      "Units in LSTM layer: 20, MSE is: 80276432.7504\n",
      "Units in LSTM layer: 25, MSE is: 44778358562.8239\n",
      "Units in LSTM layer: 30, MSE is: 114814121.3567\n",
      "Prediction of model with 30:\n",
      "    real value  predicted value  difference\n",
      "0            3     3.000000e+00         0.0\n",
      "1            6     6.000000e+00         0.0\n",
      "2           12     1.200000e+01         0.0\n",
      "3           24     2.400000e+01         0.0\n",
      "4           48     4.802300e+01         0.0\n",
      "5           96     9.611600e+01         0.1\n",
      "6          192     1.921420e+02         0.1\n",
      "7          384     3.844020e+02         0.4\n",
      "8          768     7.689990e+02         1.0\n",
      "9         1536     1.538456e+03         2.5\n",
      "10        3072     3.083775e+03        11.8\n",
      "11        6144     6.164287e+03        20.3\n",
      "12       12288     1.232814e+04        40.1\n",
      "13       24576     2.466162e+04        85.6\n",
      "14       49152     4.932850e+04       176.5\n",
      "15       98304     9.864782e+04       343.8\n",
      "16      196608     1.973000e+05       692.0\n",
      "17      393216     3.946108e+05      1394.8\n",
      "18      786432     7.892168e+05      2784.8\n",
      "19     1572864     1.578420e+06      5556.5\n",
      "20     3145728     3.156858e+06     11129.5\n",
      "21     6291456     6.313720e+06     22263.5\n",
      "22    12582912     1.262741e+07     44497.0\n",
      "Units in LSTM layer: 35, MSE is: 31636180.7715\n",
      "Units in LSTM layer: 40, MSE is: 14194971.3984\n",
      "Prediction of model with 40:\n",
      "    real value  predicted value  difference\n",
      "0            3     3.000000e+00         0.0\n",
      "1            6     6.000000e+00         0.0\n",
      "2           12     1.200000e+01         0.0\n",
      "3           24     2.400000e+01         0.0\n",
      "4           48     4.796300e+01         0.0\n",
      "5           96     9.619200e+01         0.2\n",
      "6          192     1.920830e+02         0.1\n",
      "7          384     3.841750e+02         0.2\n",
      "8          768     7.682020e+02         0.2\n",
      "9         1536     1.536457e+03         0.5\n",
      "10        3072     3.076391e+03         4.4\n",
      "11        6144     6.151206e+03         7.2\n",
      "12       12288     1.230200e+04        14.0\n",
      "13       24576     2.460572e+04        29.7\n",
      "14       49152     4.921449e+04        62.5\n",
      "15       98304     9.842544e+04       121.4\n",
      "16      196608     1.968515e+05       243.5\n",
      "17      393216     3.937063e+05       490.3\n",
      "18      786432     7.874132e+05       981.2\n",
      "19     1572864     1.574820e+06      1956.4\n",
      "20     3145728     3.149642e+06      3914.5\n",
      "21     6291456     6.299284e+06      7828.5\n",
      "22    12582912     1.259856e+07     15645.0\n",
      "Units in LSTM layer: 45, MSE is: 80711.4813\n",
      "Units in LSTM layer: 50, MSE is: 754860.5488\n",
      "Units in LSTM layer: 55, MSE is: 978685.3445\n",
      "Units in LSTM layer: 60, MSE is: 16526094.472\n",
      "Prediction of model with 60:\n",
      "    real value  predicted value  difference\n",
      "0            3     3.000000e+00         0.0\n",
      "1            6     6.000000e+00         0.0\n",
      "2           12     1.200000e+01         0.0\n",
      "3           24     2.400000e+01         0.0\n",
      "4           48     4.799900e+01         0.0\n",
      "5           96     9.623500e+01         0.2\n",
      "6          192     1.922960e+02         0.3\n",
      "7          384     3.844180e+02         0.4\n",
      "8          768     7.690350e+02         1.0\n",
      "9         1536     1.538290e+03         2.3\n",
      "10        3072     3.074098e+03         2.1\n",
      "11        6144     6.153114e+03         9.1\n",
      "12       12288     1.230452e+04        16.5\n",
      "13       24576     2.460761e+04        31.6\n",
      "14       49152     4.921357e+04        61.6\n",
      "15       98304     9.843680e+04       132.8\n",
      "16      196608     1.968675e+05       259.5\n",
      "17      393216     3.937334e+05       517.4\n",
      "18      786432     7.874728e+05      1040.8\n",
      "19     1572864     1.574966e+06      2102.2\n",
      "20     3145728     3.149925e+06      4197.0\n",
      "21     6291456     6.299875e+06      8419.0\n",
      "22    12582912     1.259982e+07     16904.0\n"
     ]
    }
   ],
   "source": [
    "units_number = list(range(1, 11)) + list(range(15, 65, 5))\n",
    "losses = []\n",
    "min_loss = None\n",
    "min_unit = None\n",
    "\n",
    "for unit in units_number: \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(unit, activation='softplus', input_shape=(n_steps, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=800, validation_split=0.2, verbose=0)\n",
    "\n",
    "    predict_y = predict(sequence, model)\n",
    "    mse = mean_squared_error(sequence, predict_y)\n",
    "    if min_loss is None or mse < min_loss:\n",
    "        min_unit = unit\n",
    "        min_loss = mse\n",
    "        best_model = model\n",
    "    losses.append(mse)\n",
    "    \n",
    "    print(f'Units in LSTM layer: {unit}, MSE is: {np.round(mse, 4)}')\n",
    "    if unit in (3, 7, 15, 30, 40, 60):\n",
    "        plot_difference(sequence, predict_y, unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1009,
     "status": "ok",
     "timestamp": 1588930511404,
     "user": {
      "displayName": "Анжелла Панкратова",
      "photoUrl": "https://lh6.googleusercontent.com/-hkI5RCmUZFM/AAAAAAAAAAI/AAAAAAAAADg/sJvW0KD7Luw/s64/photo.jpg",
      "userId": "10606067150129738728"
     },
     "user_tz": -180
    },
    "id": "ee0-S-HONx5N",
    "outputId": "647465fb-db21-4c34-f092-9134243f1907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse is 4727.6534022197275\n",
      "Prediction of model with 45:\n",
      "    real value  predicted value  difference\n",
      "0            5            5.000         0.0\n",
      "1           10           10.000         0.0\n",
      "2           20           20.000         0.0\n",
      "3           40           40.000         0.0\n",
      "4           80           79.986         0.0\n",
      "5          160          159.883         0.1\n",
      "6          320          320.002         0.0\n",
      "7          640          639.836         0.2\n",
      "8         1280         1279.843         0.2\n",
      "9         2560         2559.979         0.0\n",
      "10        5120         5119.506         0.5\n",
      "11       10240        10243.703         3.7\n",
      "12       20480        20483.930         3.9\n",
      "13       40960        40966.805         6.8\n",
      "14       81920        81932.781        12.8\n",
      "15      163840       163871.109        31.1\n",
      "16      327680       327726.219        46.2\n",
      "17      655360       655441.188        81.2\n",
      "18     1310720      1310864.000       144.0\n",
      "19     2621440      2621692.750       252.8\n"
     ]
    }
   ],
   "source": [
    "sequence = generate_test_values(5, 20, 2)\n",
    "predict_y = predict(sequence, best_model)\n",
    "mse = mean_squared_error(sequence, predict_y)\n",
    "print(f'mse is {mse}')\n",
    "plot_difference(sequence, predict_y, min_unit)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/2+rmr8311/OgYCyx9DLk",
   "collapsed_sections": [],
   "name": "Copy of Recurrence relations (p=1).ipynb",
   "provenance": [
    {
     "file_id": "12puPI80zrtSxuGTu14RJmWFeHuWSzWxN",
     "timestamp": 1588162906675
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
